{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83804d64",
   "metadata": {},
   "source": [
    "# HW1-2: Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "TORCH_CUDA_ARCH_LIST=\"8.6\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transformtransforms\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "Project_PATH = os.path.dirname(os.path.abspath('__file__'))\n",
    "outputs_dir = Project_PATH + '/'\n",
    "model_path = Project_PATH + '/save_models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12927d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "device_default = torch.cuda.current_device()\n",
    "torch.cuda.device(device_default)\n",
    "print(torch.cuda.get_device_name(device_default))\n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa39f72",
   "metadata": {},
   "source": [
    "## HW1-2 Visualize the Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7504f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_MNIST, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(28*28, 32),nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(32, 16),nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(16, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x) \n",
    "        x = self.layer2(x)    \n",
    "        x = self.layer3(x)    \n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\")\n",
    "Model_DNN_MNIST = DNN_MNIST().to(device)\n",
    "summary(Model_DNN_MNIST, input_size=(1,28*28))\n",
    "\n",
    "\n",
    "class CNN_CIFAR_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR_3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 10, 3),nn.BatchNorm2d(10),nn.ReLU(True),nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(10, 16, 3),nn.BatchNorm2d(16),nn.ReLU(True),nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(16, 32, 3),nn.BatchNorm2d(32),nn.ReLU(True))\n",
    "        self.layer4 = nn.Sequential(nn.Linear(32*4*4, 64),nn.BatchNorm1d(64),nn.ReLU(True))\n",
    "        self.layer5 = nn.Sequential(nn.Linear(64, 16),nn.BatchNorm1d(16),nn.ReLU(True))\n",
    "        self.layer6 = nn.Sequential(nn.Linear(16, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x) \n",
    "        x = self.layer2(x)    \n",
    "        x = self.layer3(x) \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.layer4(x)    \n",
    "        x = self.layer5(x)    \n",
    "        x = self.layer6(x)    \n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\")\n",
    "Model = CNN_CIFAR_3().to(device)\n",
    "summary(Model, input_size=(3,32,32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6934a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "TORCH_CUDA_ARCH_LIST=\"8.6\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "\n",
    "def train(model_name, Epochs=20, Batch=2000, Data_workers=0, LR=0.1):\n",
    "    '''\n",
    "    Load datasets\n",
    "    '''\n",
    "#     transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "#     trainset = torchvision.datasets.CIFAR10(root='./data/',train=True,download=True,transform=transform)\n",
    "#     testset = torchvision.datasets.CIFAR10(root='./data/',train=False,download=True,transform=transform)\n",
    "    trainset = torchvision.datasets.MNIST(root='./data/',train=True,download=True,transform=transforms.ToTensor())\n",
    "    testset = torchvision.datasets.MNIST(root='./data/',train=False,download=True,transform=transforms.ToTensor())\n",
    "    trainloader = DataLoader(trainset, batch_size=Batch, shuffle=True, num_workers=Data_workers)\n",
    "    testloader  = DataLoader(testset,  batch_size=Batch, shuffle=True, num_workers=Data_workers)\n",
    "    print(trainset.classes)\n",
    "    print(trainset.data.shape)\n",
    "    print(testset.data.shape)\n",
    "    torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    Model = model_name().to(device)\n",
    "#     print(Model)\n",
    "    num_param = sum(param.numel() for param in Model.parameters())\n",
    "    print('# of total parameters: ', num_param)\n",
    "    '''\n",
    "    loss & optimizer\n",
    "    '''\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(Model.parameters(), lr=LR, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.8)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    trainloss_list = []\n",
    "    testloss_list  = []\n",
    "    accuracy_list  = []\n",
    "    lr_list = []\n",
    "    w = []\n",
    "    w_1 = []\n",
    "    w_loss = []\n",
    "    grad_list = []\n",
    "    for epoch in range(Epochs):\n",
    "        Model.train()\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            images, labels = data\n",
    "#             images = images.to(device)\n",
    "            images = (images.view(-1, 28*28)).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = Model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        '''\n",
    "        Evaluating\n",
    "        '''\n",
    "        Model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "#                 images = images.to(device)\n",
    "                images = (images.view(-1, 28*28)).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = Model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                correct += (pred == labels).cpu().sum()\n",
    "            total = len(testloader.dataset)\n",
    "            accuracy = 100.0*correct/total\n",
    "        '''\n",
    "        Save loss\n",
    "        '''\n",
    "        lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        trainloss_list.append(train_loss)\n",
    "        testloss_list.append(test_loss)\n",
    "        accuracy_list.append(accuracy)\n",
    "        print('{}/{} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "                epoch, Epochs,test_loss, correct, total, accuracy))\n",
    "        '''\n",
    "        Weight collect\n",
    "        '''\n",
    "        if epoch % 1 == 0:\n",
    "            # Layer weights\n",
    "            weights_layer = np.zeros(0)\n",
    "            for name,parameters in Model.named_parameters():\n",
    "                if name == 'layer2.0.weight':\n",
    "#                     print(name)\n",
    "                    weight_i = (parameters.detach().cpu().numpy().reshape(-1))\n",
    "                    weights_layer = np.concatenate((weights_layer, weight_i))\n",
    "                    break\n",
    "            print(weights_layer.shape)\n",
    "            w_1.append(weights_layer)\n",
    "            \n",
    "            # Total weights\n",
    "            weights = np.zeros(0)\n",
    "            for name,parameters in Model.named_parameters():\n",
    "                if name[-6:] == 'weight':\n",
    "                    weight_i = (parameters.detach().cpu().numpy().reshape(-1))\n",
    "                    weights = np.concatenate((weights, weight_i))\n",
    "            print(weights.shape)\n",
    "            w.append(weights)\n",
    "            w_loss.append(train_loss)\n",
    "        '''\n",
    "        Grad collect\n",
    "        '''\n",
    "        grad_all = 0.0\n",
    "        for p in Model.parameters():\n",
    "            grad = 0.0\n",
    "            if p.grad is not None:\n",
    "                grad = (p.grad.cpu().data.numpy()**2).sum()\n",
    "            grad_all += grad\n",
    "        grad_list.append(grad_all**0.5)\n",
    "        \n",
    "    return [trainloss_list,\n",
    "            testloss_list,\n",
    "            accuracy_list,\n",
    "            lr_list,\n",
    "            w,\n",
    "            w_1,\n",
    "            w_loss,\n",
    "            grad_list]\n",
    "    \n",
    "# [trainloss_list,testloss_list,accuracy_list,lr_list,w,w_loss,grad_list] = train(CNN_CIFAR_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a3134",
   "metadata": {},
   "source": [
    "### Collect weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = 8\n",
    "W = []\n",
    "W_loss = []\n",
    "W_1 = []\n",
    "G = []\n",
    "\n",
    "for i in range(events):\n",
    "    print('Event: '+str(i+1))\n",
    "    #     DNN_MNIST\n",
    "    #     CNN_CIFAR_3\n",
    "    \n",
    "    [_,_,_,_,w,w_1,w_loss,grad_list] = train(DNN_MNIST)\n",
    "    W.append(w)\n",
    "    W_1.append(w_1)\n",
    "    W_loss.append(w_loss)\n",
    "    G.append(grad_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59259a6",
   "metadata": {},
   "source": [
    "print(np.array(W).shape)\n",
    "print(np.array(W_1).shape)\n",
    "W_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8788a",
   "metadata": {},
   "source": [
    "w = np.array(w)\n",
    "print(w.shape)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(w)\n",
    "w_new = pca.transform(w)\n",
    "\n",
    "print(w_new)\n",
    "plt.scatter(w_new[:,0],w_new[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a4658",
   "metadata": {},
   "source": [
    "### PCA reduce dimention to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def W_2(W_i):\n",
    "    w = np.array(W_i)\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(w)\n",
    "    w_new = pca.transform(w)\n",
    "    return w_new\n",
    "W_pca = []\n",
    "for i in range(events):\n",
    "    w_pca = W_2(W[i])\n",
    "    W_pca.append(w_pca)\n",
    "W_pca = np.array(W_pca)\n",
    "\n",
    "# print(W_pca.shape)    \n",
    "# print(W_pca[0].shape)\n",
    "# print(W_pca)\n",
    "\n",
    "W_1_pca = []\n",
    "for i in range(events):\n",
    "    w_1_pca = W_2(W_1[i])\n",
    "    W_1_pca.append(w_1_pca)\n",
    "W_1_pca = np.array(W_1_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ab220",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('w1',fontsize=20)\n",
    "plt.ylabel('w2',fontsize=20)\n",
    "plt.title('Model Weights',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "for i in range(events):\n",
    "    W_i = W_pca[i]\n",
    "    plt.scatter(W_i[:,0], W_i[:,1])\n",
    "    for j in range(len(W_i)):\n",
    "        plt.annotate(round(W_loss[i][j],1), (W_i[j,0],W_i[j,1]))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('w1',fontsize=20)\n",
    "plt.ylabel('w2',fontsize=20)\n",
    "plt.title('Layer Weights',fontsize=20)\n",
    "for i in range(events):\n",
    "    W_i = W_1_pca[i]\n",
    "    plt.scatter(W_i[:,0], W_i[:,1])\n",
    "    for j in range(len(W_i)):\n",
    "        plt.annotate(round(W_loss[i][j],1), (W_i[j,0],W_i[j,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f0151",
   "metadata": {},
   "source": [
    "## Visualize error surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "    \n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "W_all = W_pca.reshape((events*len(W_pca[0]),2))\n",
    "W_loss_all = np.array(W_loss)\n",
    "W_loss_all = W_loss_all.reshape(-1)\n",
    "# print(W_loss_all)\n",
    "\n",
    "x = np.linspace(0,10,10)\n",
    "y = np.linspace(0,10,10)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "z = X-X\n",
    "\n",
    "error = (W_all-np.min(W_all))/(np.max(W_all)-np.min(W_all))\n",
    "error[error==1] = 0.99\n",
    "\n",
    "for i in range(len(error[:,0])):\n",
    "    zx = ((error[i,0])*10).astype(np.int)\n",
    "    zy = ((error[i,1])*10).astype(np.int)\n",
    "#     print(zx,zy,W_loss_all[i])\n",
    "    z[zx,zy] = W_loss_all[i]\n",
    "    \n",
    "\n",
    "ax.plot_surface(X, Y, z, cmap='rainbow')\n",
    "ax.view_init(elev=30, azim=-15)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11797337",
   "metadata": {},
   "source": [
    "## HW1-2 Observe Gradient Norm During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca30f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_MNIST_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_MNIST_3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(1, 32),nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(32, 16),nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(16, 1))\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x) \n",
    "        x = self.layer2(x)    \n",
    "        x = self.layer3(x)    \n",
    "        return x\n",
    "    \n",
    "# device = torch.device(\"cuda\")\n",
    "# Model_DNN_MNIST = DNN_MNIST().to(device)\n",
    "# summary(Model_DNN_MNIST, input_size=(1000,28*28))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "Model = DNN_MNIST_3().to(device)\n",
    "summary(Model, (1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initiate data\n",
    "'''\n",
    "x = torch.linspace(0,1,1000).unsqueeze(1)\n",
    "\n",
    "y = torch.sin(5*np.pi*x)/(5*np.pi*x)\n",
    "y[0] = y[1]\n",
    "func_1 = y\n",
    "\n",
    "'''\n",
    "Define train function\n",
    "'''\n",
    "def train(function,\n",
    "          model_name,\n",
    "          Epochs = 20000,\n",
    "          Batch  = 1000,\n",
    "          Data_workers = 0,\n",
    "          LR = 0.0005):\n",
    "    '''\n",
    "    Initiate model\n",
    "    '''\n",
    "    torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "    Model = model_name().to(device)\n",
    "    x = torch.linspace(0,1,1000).unsqueeze(1)\n",
    "    x = x.to(device)\n",
    "    y = function.to(device)\n",
    "    '''\n",
    "    loss & optimizer\n",
    "    '''\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(Model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma = 0.8)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    trainloss_list = []\n",
    "    lr_list = []\n",
    "    grad_list = []\n",
    "    for epoch in range(Epochs):\n",
    "        Model.train()\n",
    "        train_loss = 0.0\n",
    "        y_pred = Model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "        trainloss_list.append(train_loss)\n",
    "#         if epoch >= Epochs//2:\n",
    "#             scheduler.step()\n",
    "        if epoch % (Epochs//10) == 0:\n",
    "            print('{}/{}, loss: {}'.format(epoch,Epochs,train_loss))\n",
    "        lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        \n",
    "        '''\n",
    "        Grad collect\n",
    "        '''\n",
    "        grad_all = 0.0\n",
    "        for p in Model.parameters():\n",
    "            grad = 0.0\n",
    "            if p.grad is not None:\n",
    "                grad = (p.grad.cpu().data.numpy()**2).sum()\n",
    "            grad_all += grad\n",
    "        grad_list.append(grad_all**0.5)\n",
    "            \n",
    "    return [Model,trainloss_list,lr_list,grad_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a241ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Model,trainloss,lr,grad_list] = train(func_1, DNN_MNIST_3, Epochs=20000, Batch=1000, Data_workers=0, LR=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ab1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.array(trainloss)**0.2, label='train_loss')\n",
    "plt.xlabel('epoch',fontsize=20)\n",
    "plt.ylabel('loss',fontsize=20)\n",
    "plt.title('sin(5*np.pi*x)/(5*np.pi*x)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.array(grad_list)**1, label='grad')\n",
    "plt.xlabel('epoch',fontsize=20)\n",
    "plt.ylabel('gard',fontsize=20)\n",
    "plt.title('sin(5*np.pi*x)/(5*np.pi*x)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9855d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
